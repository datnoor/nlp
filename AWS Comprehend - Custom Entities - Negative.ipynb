{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1099b04396475b6a0143fa303da9fa44ad87b660"
   },
   "source": [
    "# How to prepare a dataset and submit a custom entity in Amazon Comprehend\n",
    "\n",
    "This notebook covers how to prepare a training dataset for custom entities in Amazon Comprehend\n",
    "\n",
    "More information on how to create a custom entity recognizer model can be found here.\n",
    "\n",
    "https://docs.aws.amazon.com/comprehend/latest/dg/training-recognizers.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# library imports\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "54e810d8b9c1936c8569093badabc4d7b25ea881"
   },
   "source": [
    "In this example we will be using the following tweet dataset. https://www.kaggle.com/thoughtvector/customer-support-on-twitter\n",
    "First lets get our data and process it to our needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "9365c16e4481ec49f5c084f7c3b0cf50dd55047f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32716, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@sprintcare is the worst customer service | @1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare is the worst customer service | @1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare is the worst customer service | @1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115714 y’all lie about your “great” connectio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@115714 whenever I contact customer support, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  @sprintcare is the worst customer service | @1...\n",
       "1  @sprintcare is the worst customer service | @1...\n",
       "2  @sprintcare is the worst customer service | @1...\n",
       "3  @115714 y’all lie about your “great” connectio...\n",
       "4  @115714 whenever I contact customer support, t..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames=['text'] \n",
    "tweets = pd.read_csv('./data/tweet_telco.csv',encoding='utf-8',names=colnames, header=None)\n",
    "print(tweets.shape)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "845eba8749f15e1e2b10aa43414f40860259f4e0"
   },
   "source": [
    "<a id='data-wrangling'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create our dataset we need to provide an entity list for our new class named NEGATIVITY.\n",
    "\n",
    "In order to find relevant entities, you can load a corpus into a word2vec model and find similar words.\n",
    "\n",
    "For our purpose of finding devices, we will match different spellings of iPhone and Android."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words = ['Really', 'cheated', 'annoyed', 'unhelpful', 'frustrated', 'upset' , 'unhappy', 'angry', 'badly', 'bad', 'surprised', 'sadly', 'dissatisfied', 'disappointed', 'disgusted']\n",
    "\n",
    "df_entity_list = pd.DataFrame(negative_words, columns=['Text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's add another column with our class label. This is required part of the Amazon Comprehend training dataset.\n",
    "\n",
    "More information can be found here.\n",
    "\n",
    "https://docs.aws.amazon.com/comprehend/latest/dg/cer-entity-list.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entity_list['Type'] = 'NEGATIVE'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['text'].to_csv('./data/raw_negative.csv', encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"@115911 @TMobileHelp y’all just pissed me off and I’m highly disappointed with the customer service been with y’all over 16 years FIX THIS! | @117690 Hey bro! Send me a DM, I got you 100% - https://t.co/UOOUCn8nWm *JeremyKelley\"\r\n",
      "\"@115714 sucks so bad. Always switching to roaming so they can charge me whatever the hell they want. Get a real network! | @117883 We'd be more than willing to take a look at the area for you if you can DM us a good intersection, J. :) -CDE\"\r\n",
      "\"Mad at Sprint, daughter had her phone stolen and we are getting the rum around trying to get her a new one. #Sprint  #frustrated | @117885 This is concerning to us. Please, send us a DM with more details of your issue for us to assist you further. -DP\"\r\n",
      "\"@115911 @TMobileHelp terrible customer service. 3 dysfunctional refurbished phones in 2 weeks. @115913 #badservice | @120051 Ni Nicos, thank you for reaching out to us. I replied to your DM and look forward to working with you. *JasonYaddow\"\r\n",
      "\"@115913 so upset with @115911, honestly don't know why I stay, the customer care line is so rude \"\"hold on! First tell me the reason why you are calling\"\" I'm so done! Literally cried while on the phone with them. So much emotional abuse at their hands | @122611 @115913 Hi Lizbeth. This is truly not the experience I want for you. You deserve the best customer service we've got. Send me a DM so we can get started on turning this around. https://t.co/3sF8qpf2nx *AlissaFast\"\r\n",
      "@115911 they’re so not transparent that you can speak to 9 reps and get 9 versions of their truths... #tmobilesucks #annoyedcustomer | @124339 We can understand your frustration Romy. Allow us to look into why this is happening. Please send us a DM. *KaeW\r\n",
      "\"owe to me. Truly disappointed in the customer support and over all company morals of @115911 . | @125456 James, you deserve to have your device. DM us and let's see what happened so we can turn this around for you. *JamieK\"\r\n",
      "\"In the @115714 store cancellimg my account and @sprintcare is so bad they hung up on me and the guy who works at this location #sprintsucks | @125736 Jay, we really hate to hear that you want to leave Sprint; is there anything that we can do to turn this around? -CDE\"\r\n",
      "Really sick of paying 100 a month for dropped calls and no internet service. @sprintcare is there anything you will do for me? | @125913 Can you please send me a DM so that I can take a look at your concern? -BJ https://t.co/rMApsV8PQY\r\n",
      "@115911 why does our coverage suck soooo bad in rural areas? | @127781 What rural areas are you referring to Domino? Let us know those location in a DM so that we can look into it. *KaeW\r\n"
     ]
    }
   ],
   "source": [
    "!head ./data/raw_negative.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the entity list file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_telco_final[['Text', 'Type']].head(10000).to_csv('./data/entity_negative_list.csv', encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text,Type\r\n",
      "disappointed,NEGATIVE\r\n",
      "bad,NEGATIVE\r\n",
      "frustrated,NEGATIVE\r\n",
      "bad,NEGATIVE\r\n",
      "upset,NEGATIVE\r\n",
      "annoyed,NEGATIVE\r\n",
      "disappointed,NEGATIVE\r\n",
      "bad,NEGATIVE\r\n",
      "Really,NEGATIVE\r\n"
     ]
    }
   ],
   "source": [
    "!head ./data/entity_negative_list.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a test file from our original telco tweet dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_telco['text'].tail(10000).to_csv('./data/telco_device_test.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our model\n",
    "\n",
    "I am going to use the console to submit our custom entity recognizer job.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our custom entity model\n",
    "\n",
    "Let's invoke the Comprehend API to run our test job from the test file we prepared earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws comprehend start-entities-detection-job \\\n",
    "     --entity-recognizer-arn \"arn:aws:comprehend:us-east-1:202860692096:entity-recognizer/Negativity-copy\" \\\n",
    "     --job-name Test \\\n",
    "     --data-access-role-arn \"arn:aws:iam::202860692096:role/service-role/AmazonComprehendServiceRole-AmazonComprehendServiceRole\" \\\n",
    "     --language-code en \\\n",
    "     --input-data-config \"S3Uri=s3://data-phi/telco_random.csv\" \\\n",
    "     --output-data-config \"S3Uri=s3://data-phi/telco_negative\" \\\n",
    "     --region \"us-east-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "39751a13337cd09b32588e2d0fc5f7e7817cca8b"
   },
   "source": [
    "The output will be a json file specified in my --output-data-config.\n",
    "You can use Glue and Athena to inspect the results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
