{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1099b04396475b6a0143fa303da9fa44ad87b660"
   },
   "source": [
    "# Customer Support meets Spacy Universe\n",
    "\n",
    "This analysis delves into a large dataset of about 3 million tweets focusing around Customer Support queries and responses. Let's see what we can find and explore what the wonderful Spacy library and its ecosystem has to offer, documenting the trial and errors, ideas and possible further analysis along the way.\n",
    "\n",
    "**Contents : **\n",
    "\n",
    "*  [Data Wrangling](#data-wrangling)\n",
    "*  [Visualisation](#visual)\n",
    "*  [Houston! We have a problem!](#problem)\n",
    "*  [Emojis with spacymoji](#emojis)\n",
    "*  [Sentimental Emojis!](#senti)\n",
    "*  [Scattertext - a hidden gem in the Spacy Universe](#scatter)\n",
    "*  [Word Embedding projection plots using Scattertext](#embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge -y textblob scattertext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy_cld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEDCAYAAAAm3zNHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAA6tJREFUeJzt1cENwCAQwLDS/Xc+RiA/hGRPkF/WzHwAcPLfDgDgDYYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAYhgAJIYBQGIYACSGAUBiGAAkhgFAsgEB4wUDlLbWhgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# library imports\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "#matplotlib.style.use('ggplot')\n",
    "import matplotlib.pyplot as plt\n",
    "width = 0.75\n",
    "plt.rcParams['xtick.labelsize'] = 15\n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "plt.axis('off')\n",
    "#from nltk.corpus import stopwords\n",
    "#from textblob import TextBlob\n",
    "#import scattertext as st\n",
    "#import spacy\n",
    "#import spacy_cld\n",
    "\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import display, HTML\n",
    "from collections import Counter\n",
    "#from tqdm import tqdm_notebook as tqdm  # cool progress bars\n",
    "#tqdm().pandas()  # Enable tracking of progress in dataframe `apply` calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "54e810d8b9c1936c8569093badabc4d7b25ea881"
   },
   "source": [
    "First lets get our data and process it to our needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "9365c16e4481ec49f5c084f7c3b0cf50dd55047f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2811774, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   author_id  inbound                      created_at  \\\n",
       "0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @115712 I understand. I would like to assist y...                 2   \n",
       "1      @sprintcare and how do you propose we do that               NaN   \n",
       "2  @sprintcare I have sent several private messag...                 1   \n",
       "3  @115712 Please send us a Private Message so th...                 3   \n",
       "4                                 @sprintcare I did.                 4   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      3.0  \n",
       "1                      1.0  \n",
       "2                      4.0  \n",
       "3                      5.0  \n",
       "4                      6.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('../twcs.csv',encoding='utf-8')\n",
    "print(tweets.shape)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "845eba8749f15e1e2b10aa43414f40860259f4e0"
   },
   "source": [
    "<a id='data-wrangling'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5e053048057a5566a30aab3f0278aa529449938a"
   },
   "source": [
    "## Data Wrangling\n",
    "\n",
    "This is a very interesting tweet data set, about 3 million tweets, and we have information on the author of the tweets and whether the tweet was a query or a response (the \"inbound\" column). If the tweet was a query, the response_tweet_id gives the response made by the support team.\n",
    "\n",
    "It would be interesting to modify this dataframe to get query - response pairs in every row.\n",
    "The following code, to do just what we want, was pulled from [this kernel](https://www.kaggle.com/soaxelbrooke/first-inbound-and-response-tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (794299, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id_x</th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>inbound_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>response_tweet_id_x</th>\n",
       "      <th>in_response_to_tweet_id_x</th>\n",
       "      <th>tweet_id_y</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>inbound_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "      <th>response_tweet_id_y</th>\n",
       "      <th>in_response_to_tweet_id_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:46:24 +0000 2017</td>\n",
       "      <td>@115712 Can you please send us a private messa...</td>\n",
       "      <td>5,7</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:46:14 +0000 2017</td>\n",
       "      <td>@115712 I would love the chance to review the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:45:59 +0000 2017</td>\n",
       "      <td>@115712 Hello! We never like our customers to ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>115713</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 19:56:01 +0000 2017</td>\n",
       "      <td>@115714 y’all lie about your “great” connectio...</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 19:59:13 +0000 2017</td>\n",
       "      <td>@115713 H there! We'd definitely like to work ...</td>\n",
       "      <td>16</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>115715</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:03:34 +0000 2017</td>\n",
       "      <td>@115714 whenever I contact customer support, t...</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:10 +0000 2017</td>\n",
       "      <td>@115715 Please send me a private message so th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tweet_id_x author_id_x  inbound_x                    created_at_x  \\\n",
       "0          8      115712       True  Tue Oct 31 21:45:10 +0000 2017   \n",
       "1          8      115712       True  Tue Oct 31 21:45:10 +0000 2017   \n",
       "2          8      115712       True  Tue Oct 31 21:45:10 +0000 2017   \n",
       "3         18      115713       True  Tue Oct 31 19:56:01 +0000 2017   \n",
       "4         20      115715       True  Tue Oct 31 22:03:34 +0000 2017   \n",
       "\n",
       "                                              text_x response_tweet_id_x  \\\n",
       "0          @sprintcare is the worst customer service              9,6,10   \n",
       "1          @sprintcare is the worst customer service              9,6,10   \n",
       "2          @sprintcare is the worst customer service              9,6,10   \n",
       "3  @115714 y’all lie about your “great” connectio...                  17   \n",
       "4  @115714 whenever I contact customer support, t...                  19   \n",
       "\n",
       "   in_response_to_tweet_id_x tweet_id_y author_id_y  inbound_y  \\\n",
       "0                        NaN          6  sprintcare      False   \n",
       "1                        NaN          9  sprintcare      False   \n",
       "2                        NaN         10  sprintcare      False   \n",
       "3                        NaN         17  sprintcare      False   \n",
       "4                        NaN         19  sprintcare      False   \n",
       "\n",
       "                     created_at_y  \\\n",
       "0  Tue Oct 31 21:46:24 +0000 2017   \n",
       "1  Tue Oct 31 21:46:14 +0000 2017   \n",
       "2  Tue Oct 31 21:45:59 +0000 2017   \n",
       "3  Tue Oct 31 19:59:13 +0000 2017   \n",
       "4  Tue Oct 31 22:10:10 +0000 2017   \n",
       "\n",
       "                                              text_y response_tweet_id_y  \\\n",
       "0  @115712 Can you please send us a private messa...                 5,7   \n",
       "1  @115712 I would love the chance to review the ...                 NaN   \n",
       "2  @115712 Hello! We never like our customers to ...                 NaN   \n",
       "3  @115713 H there! We'd definitely like to work ...                  16   \n",
       "4  @115715 Please send me a private message so th...                 NaN   \n",
       "\n",
       "   in_response_to_tweet_id_y  \n",
       "0                        8.0  \n",
       "1                        8.0  \n",
       "2                        8.0  \n",
       "3                       18.0  \n",
       "4                       20.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_inbound = tweets[pd.isnull(tweets.in_response_to_tweet_id) & tweets.inbound]\n",
    "\n",
    "QnR = pd.merge(first_inbound, tweets, left_on='tweet_id', \n",
    "                                  right_on='in_response_to_tweet_id')\n",
    "\n",
    "# Filter to only outbound replies (from companies)\n",
    "QnR = QnR[QnR.inbound_y ^ True]\n",
    "print(f'Data shape: {QnR.shape}')\n",
    "QnR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "f76f6e558cac3965c0d53578e38c1656a96b75e7"
   },
   "outputs": [],
   "source": [
    "# removing anonymized screen names \n",
    "def sn_replace(match):\n",
    "    _sn = match.group(2).lower()\n",
    "    if not _sn.isnumeric():\n",
    "        # This is a company screen name\n",
    "        return match.group(1) + match.group(2)\n",
    "    return ''\n",
    "\n",
    "sn_re = re.compile('(\\W@|^@)([a-zA-Z0-9_]+)')\n",
    "print(\"Removing anonymized screen names in X...\")\n",
    "QnR[\"text_x\"] = QnR.text_x.progress_apply(lambda txt: sn_re.sub(sn_replace, txt))\n",
    "print(\"Removing anonymized screen names in Y...\")\n",
    "QnR[\"text_y\"] = QnR.text_y.progress_apply(lambda txt: sn_re.sub(sn_replace, txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "0428e41c670dbe801090613580cf22e3b41723b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>created_at_y</th>\n",
       "      <th>text_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115712</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>Tue Oct 31 21:46:24 +0000 2017</td>\n",
       "      <td>@115712 Can you please send us a private messa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115712</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>Tue Oct 31 21:46:14 +0000 2017</td>\n",
       "      <td>@115712 I would love the chance to review the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115712</td>\n",
       "      <td>Tue Oct 31 21:45:10 +0000 2017</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>Tue Oct 31 21:45:59 +0000 2017</td>\n",
       "      <td>@115712 Hello! We never like our customers to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115713</td>\n",
       "      <td>Tue Oct 31 19:56:01 +0000 2017</td>\n",
       "      <td>@115714 y’all lie about your “great” connectio...</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>Tue Oct 31 19:59:13 +0000 2017</td>\n",
       "      <td>@115713 H there! We'd definitely like to work ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115715</td>\n",
       "      <td>Tue Oct 31 22:03:34 +0000 2017</td>\n",
       "      <td>@115714 whenever I contact customer support, t...</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>Tue Oct 31 22:10:10 +0000 2017</td>\n",
       "      <td>@115715 Please send me a private message so th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  author_id_x                    created_at_x  \\\n",
       "0      115712  Tue Oct 31 21:45:10 +0000 2017   \n",
       "1      115712  Tue Oct 31 21:45:10 +0000 2017   \n",
       "2      115712  Tue Oct 31 21:45:10 +0000 2017   \n",
       "3      115713  Tue Oct 31 19:56:01 +0000 2017   \n",
       "4      115715  Tue Oct 31 22:03:34 +0000 2017   \n",
       "\n",
       "                                              text_x author_id_y  \\\n",
       "0          @sprintcare is the worst customer service  sprintcare   \n",
       "1          @sprintcare is the worst customer service  sprintcare   \n",
       "2          @sprintcare is the worst customer service  sprintcare   \n",
       "3  @115714 y’all lie about your “great” connectio...  sprintcare   \n",
       "4  @115714 whenever I contact customer support, t...  sprintcare   \n",
       "\n",
       "                     created_at_y  \\\n",
       "0  Tue Oct 31 21:46:24 +0000 2017   \n",
       "1  Tue Oct 31 21:46:14 +0000 2017   \n",
       "2  Tue Oct 31 21:45:59 +0000 2017   \n",
       "3  Tue Oct 31 19:59:13 +0000 2017   \n",
       "4  Tue Oct 31 22:10:10 +0000 2017   \n",
       "\n",
       "                                              text_y  \n",
       "0  @115712 Can you please send us a private messa...  \n",
       "1  @115712 I would love the chance to review the ...  \n",
       "2  @115712 Hello! We never like our customers to ...  \n",
       "3  @115713 H there! We'd definitely like to work ...  \n",
       "4  @115715 Please send me a private message so th...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making sure the dataframe contains only the needed columns\n",
    "QnR = QnR[[\"author_id_x\",\"created_at_x\",\"text_x\",\"author_id_y\",\"created_at_y\",\"text_y\"]]\n",
    "QnR.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = QnR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data['text'] = tweet_data['text_x'] + ' | ' + tweet_data['text_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data['text'].sample(1000).to_csv('./tweet_random.csv', encoding='utf-8', index=False)\n",
    "#tweet_telco_negative_final['Raw_Text'].to_csv('./raw_negative.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_telco = tweet_data[tweet_data[\"author_id_y\"].isin([\"TMobileHelp\", \"sprintcare\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "tweet_telco['text'] = tweet_telco['text_x'] + ' | ' + tweet_telco['text_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "to_csv() got an unexpected keyword argument 'doublequote'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-bb1bc9ded13f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtweet_telco_text\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtweet_telco\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtweet_telco_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./tweet_telco.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtweet_telco_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: to_csv() got an unexpected keyword argument 'doublequote'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "tweet_telco_text= tweet_telco[[\"text\"]]\n",
    "tweet_telco_text['text'].to_csv('./tweet_telco.csv', encoding='utf-8', index=False, header=False, doublequote=False)\n",
    "tweet_telco_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@sprintcare is the worst customer service | @1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare is the worst customer service | @1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare is the worst customer service | @1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115714 y’all lie about your “great” connectio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@115714 whenever I contact customer support, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  @sprintcare is the worst customer service | @1...\n",
       "1  @sprintcare is the worst customer service | @1...\n",
       "2  @sprintcare is the worst customer service | @1...\n",
       "3  @115714 y’all lie about your “great” connectio...\n",
       "4  @115714 whenever I contact customer support, t..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_telco_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_telco_text_negative = tweet_telco_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "To print out without the quotes.\n",
    ">> df.to_csv(\"out.tsv\", , sep=\"\\t\", quoting=csv.QUOTE_NONE, quotechar=\"\",  escapechar=\"\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head tweet_telco.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tweet_telco_text_negative['match']=tweet_telco_text['text'].str.extract(r'(Really|cheated|annoyed|unhelpful|frustrated|upset|unhappy|angry|badly|bad|surprised|sadly|dissatisfied|disappointed|disgusted)', expand=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@sprintcare is the worst customer service | @1...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare is the worst customer service | @1...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare is the worst customer service | @1...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115714 y’all lie about your “great” connectio...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@115714 whenever I contact customer support, t...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>@115913 @115911 just called in to switch from ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>@TMobileHelp trying to redeem a free tuesday c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>T-Mobile So Bs My Internet Stop Working For 3 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>No. That opportunity has passed. Bad customer ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>@TMobileHelp @1247 The @10568 code is not work...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>@115714 fuck you fix my connection | @115950 T...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>@115714 @sprintcare how can I get in touch wit...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>@115714 @sprintcare how can I get in touch wit...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>@115913 I'm a #TMobile customer getting the ru...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>@115913 I'm a #TMobile customer getting the ru...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>@115913 I'm a #TMobile customer getting the ru...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>@115714 you wanna actually turn on your intern...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>@115911    Who’s looking in your window at nig...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>Finally free of the @115911 chains here I come...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>@115911 @TMobileHelp when is the 600mhz coming...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>@115911 once again you are being slow 😑 | @116...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>@115714 customer service 👎! 4 different people...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>@115714 chk ur latest bill. I paid for note 8 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>@115714 is honestly trash | @116173 This is co...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>@TMobileHelp Can someone help me with a questi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>Hey @115911 how come none of the #TMobileTuesd...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>@sprintcare mine and my brothers data is barel...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>I want to go see to @115725 and leave @115714 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>@116447 - And the issue is still not fixed!  N...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>@115911 how much for the iPhone x with the jum...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>@115911 @ATT @115714 @115725 .  I currently ha...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>@115911 @ATT @115714 @115725 .  I currently ha...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>@115911 why is your network sucking in the mid...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>@115911 @TMobileHelp y’all just pissed me off ...</td>\n",
       "      <td>disappointed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>What’s wrong with my service @TMobileHelp. Yes...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>@115714’s service is 🚮 my bill is wayyy too mu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>@67723 Could you confirm @115714 falls within ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>I didn't get this!! 😩😩 https://t.co/Nj8L7XP9YG...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>@115911 you need to get with @698 I have no se...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>Does @115911 even have LTE? Barely ever wants ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>@115913  wow, I've never felt so disrespected ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>@TMobileHelp what's with these speeds in Deer ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2669</th>\n",
       "      <td>Yah know... I'm really really really tired of ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>Hold on... how?... nvm https://t.co/xgcksSyWqV...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>@115714 sucks so bad. Always switching to roam...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>Sad when you have been a customer for over 18 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>Mad at Sprint, daughter had her phone stolen a...</td>\n",
       "      <td>frustrated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>Hi @115913, why can't I get service in William...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2789</th>\n",
       "      <td>I’ve been stuck on a bus trying to leave Seatt...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791</th>\n",
       "      <td>@TMobileHelp are iPhone X preorders going to c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792</th>\n",
       "      <td>@TMobileHelp could one of you beautiful humans...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2794</th>\n",
       "      <td>@115911 can i use my jumpstart towards getting...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>@115911 Hi,Right now our 2phones are in my nam...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>@sprintcare is there any news on when the WiFi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>@115714 what’s going on with my service ? | @1...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>Preordered my #iPhoneX on time before 5 on the...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>Preordered my #iPhoneX on time before 5 on the...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926</th>\n",
       "      <td>@TMobileHelp My \"This One's on Us\" seems to ha...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>@115911 \\nMy dunkin donut $2 promo does not wo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2954</th>\n",
       "      <td>Been calling sprint all week! Been on hold for...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text         match\n",
       "0     @sprintcare is the worst customer service | @1...           NaN\n",
       "1     @sprintcare is the worst customer service | @1...           NaN\n",
       "2     @sprintcare is the worst customer service | @1...           NaN\n",
       "3     @115714 y’all lie about your “great” connectio...           NaN\n",
       "4     @115714 whenever I contact customer support, t...           NaN\n",
       "251   @115913 @115911 just called in to switch from ...           NaN\n",
       "252   @TMobileHelp trying to redeem a free tuesday c...           NaN\n",
       "253   T-Mobile So Bs My Internet Stop Working For 3 ...           NaN\n",
       "254   No. That opportunity has passed. Bad customer ...           NaN\n",
       "255   @TMobileHelp @1247 The @10568 code is not work...           NaN\n",
       "279   @115714 fuck you fix my connection | @115950 T...           NaN\n",
       "280   @115714 @sprintcare how can I get in touch wit...           NaN\n",
       "281   @115714 @sprintcare how can I get in touch wit...           NaN\n",
       "282   @115913 I'm a #TMobile customer getting the ru...           NaN\n",
       "283   @115913 I'm a #TMobile customer getting the ru...           NaN\n",
       "284   @115913 I'm a #TMobile customer getting the ru...           NaN\n",
       "292   @115714 you wanna actually turn on your intern...           NaN\n",
       "482   @115911    Who’s looking in your window at nig...           NaN\n",
       "503   Finally free of the @115911 chains here I come...           NaN\n",
       "540   @115911 @TMobileHelp when is the 600mhz coming...           NaN\n",
       "541   @115911 once again you are being slow 😑 | @116...           NaN\n",
       "557   @115714 customer service 👎! 4 different people...           NaN\n",
       "558   @115714 chk ur latest bill. I paid for note 8 ...           NaN\n",
       "559   @115714 is honestly trash | @116173 This is co...           NaN\n",
       "883   @TMobileHelp Can someone help me with a questi...           NaN\n",
       "884   Hey @115911 how come none of the #TMobileTuesd...           NaN\n",
       "896   @sprintcare mine and my brothers data is barel...           NaN\n",
       "897   I want to go see to @115725 and leave @115714 ...           NaN\n",
       "898   @116447 - And the issue is still not fixed!  N...           NaN\n",
       "1128  @115911 how much for the iPhone x with the jum...           NaN\n",
       "...                                                 ...           ...\n",
       "2443  @115911 @ATT @115714 @115725 .  I currently ha...           NaN\n",
       "2444  @115911 @ATT @115714 @115725 .  I currently ha...           NaN\n",
       "2445  @115911 why is your network sucking in the mid...           NaN\n",
       "2446  @115911 @TMobileHelp y’all just pissed me off ...  disappointed\n",
       "2448  What’s wrong with my service @TMobileHelp. Yes...           NaN\n",
       "2483  @115714’s service is 🚮 my bill is wayyy too mu...           NaN\n",
       "2484  @67723 Could you confirm @115714 falls within ...           NaN\n",
       "2582  I didn't get this!! 😩😩 https://t.co/Nj8L7XP9YG...           NaN\n",
       "2583  @115911 you need to get with @698 I have no se...           NaN\n",
       "2586  Does @115911 even have LTE? Barely ever wants ...           NaN\n",
       "2587  @115913  wow, I've never felt so disrespected ...           NaN\n",
       "2588  @TMobileHelp what's with these speeds in Deer ...           NaN\n",
       "2669  Yah know... I'm really really really tired of ...           NaN\n",
       "2670  Hold on... how?... nvm https://t.co/xgcksSyWqV...           NaN\n",
       "2671  @115714 sucks so bad. Always switching to roam...           bad\n",
       "2672  Sad when you have been a customer for over 18 ...           NaN\n",
       "2673  Mad at Sprint, daughter had her phone stolen a...    frustrated\n",
       "2731  Hi @115913, why can't I get service in William...           NaN\n",
       "2789  I’ve been stuck on a bus trying to leave Seatt...           NaN\n",
       "2791  @TMobileHelp are iPhone X preorders going to c...           NaN\n",
       "2792  @TMobileHelp could one of you beautiful humans...           NaN\n",
       "2794  @115911 can i use my jumpstart towards getting...           NaN\n",
       "2795  @115911 Hi,Right now our 2phones are in my nam...           NaN\n",
       "2831  @sprintcare is there any news on when the WiFi...           NaN\n",
       "2833  @115714 what’s going on with my service ? | @1...           NaN\n",
       "2835  Preordered my #iPhoneX on time before 5 on the...           NaN\n",
       "2836  Preordered my #iPhoneX on time before 5 on the...           NaN\n",
       "2926  @TMobileHelp My \"This One's on Us\" seems to ha...           NaN\n",
       "2927  @115911 \\nMy dunkin donut $2 promo does not wo...           NaN\n",
       "2954  Been calling sprint all week! Been on hold for...           NaN\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_telco_text_negative.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_telco_negative_final = tweet_telco_text_negative[tweet_telco_text_negative['match'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "tweet_telco_negative_final['Type'] = 'NEGATIVE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_telco_negative_final = tweet_telco_negative_final.rename(index=str, columns={\"text\": \"Raw_Text\", \"match\": \"Text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Raw_Text    1484\n",
       "Text        1484\n",
       "Type        1484\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_telco_negative_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_telco_negative_final['Raw_Text'].to_csv('./raw_negative.csv', encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_telco_negative_final[['Text', 'Type']].to_csv('./entity_list_negative.csv', encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_telco_final['Raw_Text'].tail(10000).to_csv('./telco_device_test.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws comprehend start-entities-detection-job \\\n",
    "     --entity-recognizer-arn \"arn:aws:comprehend:us-east-1:202860692096:entity-recognizer/Negativity-copy\" \\\n",
    "     --job-name Test \\\n",
    "     --data-access-role-arn \"arn:aws:iam::202860692096:role/service-role/AmazonComprehendServiceRole-AmazonComprehendServiceRole\" \\\n",
    "     --language-code en \\\n",
    "     --input-data-config \"S3Uri=s3://data-phi/telco_random.csv\" \\\n",
    "     --output-data-config \"S3Uri=s3://data-phi/telco_negative\" \\\n",
    "     --region \"us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_telco_text.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_telco[tweet_telco['text_x'].str.contains('android|Android|iphone|iPhone')].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "efeaf3b0295b82f8ccc50a8d6ed8528a2885f30a"
   },
   "source": [
    "<a id='visual'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "daa26112cd176c11219805b0c30f119a04c59f3c"
   },
   "source": [
    "Now let's get the number of tweets in the dataset for each company and plot the data where number of tweets > 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "501e6a78dc94cb660cdc15adbf048cb23091e910"
   },
   "outputs": [],
   "source": [
    "count = QnR.groupby(\"author_id_y\")[\"text_x\"].count()\n",
    "c = count[count>15000].plot(kind='barh',figsize=(10, 8), color='#619CFF', zorder=2, width=width,)\n",
    "c.set_ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0ee30b21bee5c04e3d69af83c492858c9d8cc78e"
   },
   "source": [
    "Looks like the dataset has a lot of tweets for AmazonHelp. Lets take a closer look at queries to @AmazonHelp and their responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0e44204dad8192728eb4edea746e410aca47f8c4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "amazonQnR = QnR[QnR[\"author_id_y\"]==\"AmazonHelp\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "78fdf0408fa55efb9721c6b9dfa1a32c6ab4f8f7"
   },
   "source": [
    "The last 10 queries to @AmazonHelp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0b29137c9b940ec154ed1cf4290d970a1639f9d7"
   },
   "source": [
    "<a id='problem'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "928e69bd104cce12da2af78669ff50aa30df69fe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "amazonQnR.tail(10)[\"text_x\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3b02e736e09b732dcdb0ccfa9dd3ca9df4f8569f"
   },
   "source": [
    "## Houston, we have a problem!\n",
    "\n",
    "Too many different languages! It was assumed that the dataset contained only English tweets, but as seen above, that is definitely not the case.\n",
    "\n",
    "Fortunately, the solution exists within the [spacy universe](https://spacy.io/universe/) itself! (PUN totally intended)\n",
    "\n",
    "Since version 2, spacy has support for custom \"extensions\" and the **[spacy-cld](https://github.com/nickdavidhaynes/spacy-cld) ** extension which wraps the Python wrapper of Google's `Compact Language Detector 2` is just what we require.\n",
    "\n",
    "Pluggable interfaces are so awesome!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "1ac81fe1da8e7b5a4831f6fb4265daae02e1a219"
   },
   "outputs": [],
   "source": [
    "# amazonQnR[\"text_x\"] = amazonQnR[\"text_x\"].str.encode(\"utf-8\")\n",
    "# amazonQnR[\"text_x\"] = amazonQnR[\"text_x\"].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bbeade705935004c24edb6d8d713daf791661678"
   },
   "outputs": [],
   "source": [
    "nlp_cld = spacy.load('en',disable_pipes=[\"tagger\",\"ner\"])\n",
    "language_detector = spacy_cld.LanguageDetector()\n",
    "nlp_cld.add_pipe(language_detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0ffe986975f1210cb0ba1a2bffc37cea9c13ef5b"
   },
   "source": [
    "The above code loads up a spacy pipeline disabling the tagger and ner, since we don't require it right now. Then the `spacy_cld` `LanguageDetector` pipe is added for detecting languages in the text data we have.\n",
    "\n",
    "\n",
    "The following code is an example of how `spacy_cld` adds `languages` and `language_scores`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0d534f2d57ad782c99bafc64bd9eef1167546bbf",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "doc = nlp_cld(amazonQnR.iloc[4][\"text_x\"])\n",
    "print(doc)\n",
    "print(doc._.languages)  \n",
    "print(doc._.language_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b732d28711bd895332e2c8d3d6f3d120f456f644"
   },
   "source": [
    "Let's make a mask which will allow us to select the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "7a731cb929cfb1999e4b5e358bbcd5ce15133b33",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask = []\n",
    "try:\n",
    "    for i,doc in tqdm(enumerate(nlp_cld.pipe(amazonQnR[\"text_x\"], batch_size=512))):\n",
    "            if 'en' not in doc._.languages or len(doc._.languages) != 1:\n",
    "                mask.append(False)\n",
    "            else:\n",
    "                mask.append(True)\n",
    "except Exception:\n",
    "    print(\"excepted \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "76f19f8477841be49d3fb5fe021949540b68b199"
   },
   "outputs": [],
   "source": [
    "amazonQnR = amazonQnR[mask]\n",
    "# sample a random fraction to visually ensure that we have only English tweets\n",
    "amazonQnR.sample(frac=0.0002)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8a370ac604bd93889fd8bc32fda28d53010cc3e1"
   },
   "source": [
    "Problem solved, we have removed all the text which is in a language other than English\n",
    "\n",
    "Now back to the analysis, where were we? \n",
    "Peeking into queries to @AmazonHelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3c0cd764ad4b8e0ea222e37d9253c3da81a8afe6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "amazonQnR.tail(10)[\"text_x\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1ec821fe9853d8398c9608f0e88205419d79aea4"
   },
   "source": [
    "<a id='emojis'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b49f4945b654253b362413a477a5a18e24c2138d"
   },
   "source": [
    "## Emojis with spacymoji\n",
    "\n",
    "Interestingly, during the process of cleaning our data, I saw that some queries and replies had emoji's in them. Wouldn't it be nice to know which smiley is most used by Customers in their queries and the Companies in their responses?\n",
    "\n",
    "Shout out to Spacy Universe again, with its cool extension named [spacymoji](https://github.com/ines/spacymoji/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8a203ec1af83f1455623ad607f062d6cfca2e602"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\",disable_pipes=[\"tagger\"])\n",
    "\n",
    "from spacymoji import Emoji\n",
    "emoji = Emoji(nlp)\n",
    "nlp.add_pipe(emoji, first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bdb14d31f50ba5352d01b42222141d8d50aa0e4b"
   },
   "source": [
    "While we're at it, Spacy has pretrained models for entity extraction, let's use that as well and see which product gets most queries.\n",
    "The pipes in spacy can be seen using the following code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc18444b4363325a6003eebbb2ff72435a0d665d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "0d249186d54e1f5dcf0dd77082f6a6f70e85bcee"
   },
   "outputs": [],
   "source": [
    "emojis = []\n",
    "for doc in tqdm(nlp.pipe(amazonQnR[\"text_x\"], batch_size=512)):\n",
    "    if doc._.has_emoji:\n",
    "        for e in doc._.emoji:\n",
    "            emojis.extend(e[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5838c1f5782c619c1c39ceec36beaeff494a27aa"
   },
   "source": [
    " **Emoji Count**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8d33523aba5bbd08f2b04e6c8a3eff8d37b152e7"
   },
   "source": [
    "**Top Emojis in query tweets by Customers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b45952745d7613173ca9aaf5a4c6b7929cddccf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eCount = Counter(emojis)\n",
    "eCount.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a9aa7004c6a9fd575602753f5debe3d6260888d8"
   },
   "source": [
    "As expected, the red angry face 😡, the confused 🤔and the annoyed 🙄emojis are two of the most commonly used one by customers who are clearly venting their anger, confusion and annoyance at something that went wrong and requires support.\n",
    "\n",
    "Its a little surprising to find the laughter 😂emoji being this common, but that probably indicates that twitter users are quite sarcastic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "4bdfb02e00be13ece35c3b4621f3bd9a13e2b584",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "response_emojis = []\n",
    "for doc in tqdm(nlp.pipe(amazonQnR[\"text_y\"], batch_size=512)):\n",
    "    elist = []\n",
    "    if doc._.has_emoji:\n",
    "        for e in doc._.emoji:\n",
    "            elist.append(e[0])\n",
    "    response_emojis.append(elist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "781567ca4c5a0fa0c8b51354d61256067a8bb93a"
   },
   "source": [
    "**Top Emojis in response tweets by Customer Support teams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "0429557110deda61148797c9c745c9092fd0bca7"
   },
   "outputs": [],
   "source": [
    "Counter([item for sublist in response_emojis for item in sublist]).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c9828ebd3387fe9e76ec714404be3dedc6a2ce91"
   },
   "source": [
    "My hypothesis for this result is that responses from customer support teams often do not put emojis when responding to Angry queries. They tend to respond to positive customer tweets with the smiling 😊and cheerful 😁emojis. Need to validate this hypothesis using sentiment analysis and checking for common emojis in response to positve and negative queries\n",
    "\n",
    "Let's give it a shot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e552d14853f0247d506acc80ffaafb86f95d1e50"
   },
   "source": [
    "<a id='senti'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "719531c8b58bfd003553e6b7dfd98d4d8d29f4aa"
   },
   "source": [
    "## Sentimental Emojis\n",
    "\n",
    "This is where we hit a wall in the Spacy Universe, spacy does not have a pretrained model for sentiment analysis, the reason being non availability of a good public dataset as mentioned by spacy creator Honnibal [ here](https://github.com/explosion/spaCy/issues/765#issuecomment-372058333)\n",
    "\n",
    "Here's another idea for a spacy extension - a quick, rudimentary sentiment analysis extension. If you feel inspired, go ahead and make one, while I put it on my list as well.\n",
    "\n",
    "Since we just want a quick analysis just to see whether the hypothesis is valid and are not very concerned with accuracy, lets use [vaderSentiment](https://textblob.readthedocs.io/en/dev/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "893fce9991bdb18acd077e31ec1f0077a6139cc3"
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sent_analyser = SentimentIntensityAnalyzer()\n",
    "positive_text = \"love this phone! its the best one I've owned over the years\"\n",
    "negative_text = \"what sort of company makes such products? this phone hangs up all the time and is totally useless\"\n",
    "print(\"positive_text sentiment : \",sent_analyser.polarity_scores(positive_text)[\"compound\"])\n",
    "print(\"negative_text sentiment : \",sent_analyser.polarity_scores(negative_text)[\"compound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f6e00b979cf15ca2bc20608933f3fe8fcddff117"
   },
   "outputs": [],
   "source": [
    "def sentiment(text):\n",
    "    return (sent_analyser.polarity_scores(text)[\"compound\"] + TextBlob(text).sentiment.polarity)/2\n",
    "amazonQnR[\"text_x_sentiment\"] = amazonQnR[\"text_x\"].apply(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "ecf7940f635b0be3f66d039b14308aaa5717d987"
   },
   "outputs": [],
   "source": [
    "response_emojis_for_positive_queries = []\n",
    "response_emojis_for_negative_queries = []\n",
    "for i,sentiment in enumerate(amazonQnR[\"text_x_sentiment\"]):\n",
    "    if sentiment > 0.0:\n",
    "        response_emojis_for_positive_queries.extend(response_emojis[i])\n",
    "    elif sentiment < 0.0:\n",
    "        response_emojis_for_negative_queries.extend(response_emojis[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "7f541df02a5decf8198206c40ed8dbf4c0e4ea09"
   },
   "outputs": [],
   "source": [
    "amazonQnR[amazonQnR[\"text_x_sentiment\"]>0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fbbd376f55bd5a3c8eceda65a4ccd73c9045aef0"
   },
   "source": [
    "**Emojis in responses for positive queries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8c4021c8f0c525dd9d18d52a62a2a312bce6c33c"
   },
   "outputs": [],
   "source": [
    "Counter(response_emojis_for_positive_queries).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ff8cae84025c34d8c660356958d93b7987c99ad5"
   },
   "source": [
    " **Emojis in responses for negative queries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "38489a0ed7b76b642382afb298217c2cdaec60a1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Counter(response_emojis_for_negative_queries).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "33bc4f7fba2af3f3ad032d741b6c9e937df06ed3"
   },
   "source": [
    "Looks like our hypothesis is not quite true, emoji's like 😊and 😁are used by support teams for both positive and negative customer queries. However, there is a skew in the number of tweets for each, so we need a more representative dataset and a better sentiment model to study this in depth. We'll defer that for a different session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "40dbeed8d6ae2d807f29b3ce89e2da7228fb1339"
   },
   "source": [
    "**One more look at the number of tweets per company**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "35ce5fb35789d120964a712cb97e02f405909c04"
   },
   "outputs": [],
   "source": [
    "count = QnR.groupby(\"author_id_y\")[\"text_x\"].count()\n",
    "c = count[count>15000].plot(kind='barh',figsize=(10, 8), color='#619CFF', zorder=2, width=width,)\n",
    "c.set_ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "46528649627194b11746812721ac24c2dd9f540e"
   },
   "source": [
    "There's a good number of tweets for AmericanAir, British_Airways, Delta and SouthwestAir. Since all these companies provide the same service i.e. flights, it would be interesting to do a comparison\n",
    "\n",
    "Let's first take a look specifically at American Air and British Airways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5be7346746567c54afc42999ed0be2dbd3ced50c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "airlinesQnR = QnR[(QnR[\"author_id_y\"]==\"AmericanAir\")|(QnR[\"author_id_y\"]==\"British_Airways\")]\n",
    "airlinesQnR.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "96d64badbd6dd4590d502b2dc5dab8c810663a01"
   },
   "outputs": [],
   "source": [
    "airlinesQnR[\"text_y\"] = airlinesQnR[\"text_y\"].str.lower()  \n",
    "stop = stopwords.words('english')\n",
    "big_regex = re.compile(' | '.join(stop))\n",
    "airlinesQnR[\"text_y\"].progress_apply(lambda x: big_regex.sub(\" \",x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2063a6008471ab141f97e53c3a8517e97ce57e2d"
   },
   "source": [
    "<a id='scatter'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d3e34d60cc2dc1da894917155c4223028154b22f"
   },
   "source": [
    "## Scattertext - a hidden gem in the Spacy Universe\n",
    "\n",
    "[Scattertext](https://spacy.io/universe/?id=scattertext) is an excellent exploratory text analysis tool, which I would never have stumbled on if not for spacy!\n",
    "It allows cool visualisations differentiating between the terms used by different documents using an interactive scatter plot.\n",
    "\n",
    "Let's build one to compare tweet responses by American Airlines vs British Airways :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "6b328e53322fee88647145fe5ad7e68c86b56134"
   },
   "outputs": [],
   "source": [
    "import scattertext as st\n",
    "nlp = spacy.load('en',disable_pipes=[\"tagger\",\"ner\"])\n",
    "airlinesQnR['parsed'] = airlinesQnR.text_y.progress_apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6dfdf48424884e1fa83a00f47af5286527a20d27"
   },
   "outputs": [],
   "source": [
    "corpus = st.CorpusFromParsedDocuments(airlinesQnR,\n",
    "                             category_col='author_id_y',\n",
    "                             parsed_col='parsed').build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "093671d0d876c203b2ff464cecd4de57ae12a946"
   },
   "outputs": [],
   "source": [
    "html = st.produce_scattertext_explorer(corpus,\n",
    "          category='British_Airways',\n",
    "          category_name='British Airways',\n",
    "          not_category_name='American Airlines',\n",
    "          width_in_pixels=600,\n",
    "          minimum_term_frequency=10,\n",
    "          term_significance = st.LogOddsRatioUninformativeDirichletPrior(),\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "66ecc39ecf8e29a7e8901c47e0e4f96347f81562"
   },
   "source": [
    "Since the D3 visualisation done by scattertext is real awesome, it takes up quite some time to load while viewing as a kaggle kernel and probably take more than 5 minutes to load properly. Check out version 3 or 4 of this kernel if you want to experiment ;) \n",
    "Sharing the screenshot image of the plot below.\n",
    "\n",
    "Make sure you try this kernel out, uncomment the following cell and run it to interact with the plot. It is really worth it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "db694ef342b8c1f7fa68263dc013227a17d40e9d"
   },
   "outputs": [],
   "source": [
    "# uncomment this cell to load the interactive scattertext visualisation\n",
    "# filename = \"americanAir-vs-britishAirways.html\"\n",
    "# open(filename, 'wb').write(html.encode('utf-8'))\n",
    "# IFrame(src=filename, width = 800, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ff3fc54083d3ec88ab7493b8efa3bd5ffe46eba7"
   },
   "source": [
    "![Imgur](https://i.imgur.com/uBmPKwE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "792e9d612f6266746550991cca0714d89e34b4e7"
   },
   "source": [
    "This visualisation can be overwhelming in the beginning, but on a closer look, one can find typical American Airlines references like `aateam`, `aadventures`, `faabulous` and `aadvantage` on the bottom right corner. American Airlines love to use the `double 'a'` reference quite a lot!\n",
    "British Airways responses,  on the opposite corner in blue color, seem to be very concerned about the `booking reference`\n",
    "\n",
    "Looks like American Airlines are fond of `kudos`! Try clicking on `kudos` in the chart to see some sample tweets which you can scroll through in the interactive plot. (Try it out by forking the kernel and running the commented out cell above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a531f3c40e3761fe0c47ce5af2e663a4b587a2ba"
   },
   "source": [
    "## Visualising Empath topics and categories\n",
    "\n",
    "[Empath](http://empath.stanford.edu/) is a lexical analysis research project at Stanford for Understanding Topic Signals in Large-Scale Text. Read more about it from this [research paper.](https://hci.stanford.edu/publications/2016/ethan/empath-chi-2016.pdf) \n",
    "\n",
    "Scattertext has an option for visualising Empath topics and categories, lets use that for our American Airlines vs British Airways analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "514a6d4c6ac0e38a457cb5a4b8f7da93a9da3dbe"
   },
   "outputs": [],
   "source": [
    "feat_builder = st.FeatsFromOnlyEmpath()\n",
    "empath_corpus = st.CorpusFromParsedDocuments(airlinesQnR,\n",
    "                                              category_col='author_id_y',\n",
    "                                              feats_from_spacy_doc=feat_builder,\n",
    "                                              parsed_col='parsed').build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "14973d2320c4c6de6793e44c875529302a04f31c"
   },
   "outputs": [],
   "source": [
    "html = st.produce_scattertext_explorer(empath_corpus,\n",
    "                                        category='British_Airways',\n",
    "                                        category_name='British Airways',\n",
    "                                        not_category_name='American Airlines',\n",
    "                                        width_in_pixels=700,\n",
    "                                        metadata=airlinesQnR['author_id_y'],\n",
    "                                        use_non_text_features=True,\n",
    "                                        use_full_doc=True,\n",
    "                                        topic_model_term_lists=feat_builder.get_top_model_term_lists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "78195831bca7438b1c85ac3f5631f91736df2d8e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# uncomment this cell to load the interactive scattertext visualisation\n",
    "# filename = \"empath-BA-vs-AA.html\"\n",
    "# open(filename, 'wb').write(html.encode('utf-8'))\n",
    "# IFrame(src=filename, width = 900, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c0b90b95418873ea9f8f111b51096e3ea578bcdb"
   },
   "source": [
    "![Imgur](https://i.imgur.com/Gxa086C.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b692f1d111bf65478379a7692772a8b638f7b3d8"
   },
   "source": [
    "On the top right corner, clearly `air_travel` is the most frequent topic for both British Airways and American Airlines since of-course they are flight providers. Topics `urban`, `technology` and `fun` are frequent for British Airways and topics `magic`, `cheerfulness` and `affection` are frequent for American Airlines.\n",
    "\n",
    "Try clicking on different topics to see which tweets contribute towards the different topics. (Try it out by forking the kernel and running the commented out cell above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c1a2b7847c20e2bcfc0689af09b8280c31dff2c4"
   },
   "source": [
    "<a id=\"embedding\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "482ef07da2fdeaf0c1fe6fc3443f09e5b48077b2"
   },
   "source": [
    "## Word Embedding projection plots using Scattertext\n",
    "\n",
    "Scatter text can also be used to visualize word embedding projections. We'll explore two such plots \n",
    "\n",
    "** 1. Word Association with a specific term**\n",
    "\n",
    "The first shows word associations to a specific term using Spacy's pretrained embedding vectors. Let's use this to see the terms most associated with the term `delay` since a lot of customer tweets to flight providers will be due to flight delays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0ab486d09bc2ea1d9c37b8264018765e4a1b764d"
   },
   "outputs": [],
   "source": [
    "corpus = (st.CorpusFromParsedDocuments(airlinesQnR,\n",
    "                             category_col='author_id_y',\n",
    "                             parsed_col='parsed').build().get_stoplisted_unigram_corpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ebcc9ee703427eaf67644ae042d9c4331ec88ec7"
   },
   "outputs": [],
   "source": [
    "target_term = 'delay'\n",
    "html = st.word_similarity_explorer(corpus,\n",
    "                                   category='British_Airways',\n",
    "                                   category_name='British Airways',\n",
    "                                   not_category_name='American Airlines',\n",
    "                                   target_term=target_term,\n",
    "                                   minimum_term_frequency=5,\n",
    "                                   width_in_pixels=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "fbc1fb4691c4d5f19e43b8ea34899fbbd0bf6d11"
   },
   "outputs": [],
   "source": [
    "# file_name = 'similarity.html'\n",
    "# open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "# IFrame(src=file_name, width = 1000, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6792950f439e32824945dd545c07367d0d248d41"
   },
   "source": [
    "![Imgur](https://i.imgur.com/MX7y2Dy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "452815a1e8df611abf3fbc760bd26b673f7fc9b8"
   },
   "source": [
    "At the top right corner we see the most commonly associated words with the term `delay` are `late` , `team`, `info` and `patience`. If you click on the interactive version, the list of tweets with the terms can be explored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3cfd690ddb2ed6a847f58bc8fe46ae8d50814df7"
   },
   "source": [
    "**2.  T-SNE style word embedding projection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f74b2a3c271c519b60427381015c94fdc476c8e6"
   },
   "outputs": [],
   "source": [
    "html = st.produce_projection_explorer(corpus,\n",
    "                                   category='British_Airways',\n",
    "                                   category_name='British Airways',\n",
    "                                   not_category_name='American Airlines',\n",
    "                                   width_in_pixels=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "0eb7584827e0ef1a5196b32c1a664c0ec70111cb"
   },
   "outputs": [],
   "source": [
    "# file_name = 'projection.html'\n",
    "# open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "# IFrame(src=file_name, width = 1200, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "790776814f336640ea878c3cfb4ddd6082eb6ee3"
   },
   "source": [
    "![Imgur](https://i.imgur.com/x4AM7mg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2990f0ac66e8eab691c1389e7847e916055578c0"
   },
   "source": [
    "* Very interesting to see all the different names of people clustered on the top right corner. \n",
    "* At the bottom, slightly towards right side, we see a cluster for places - heathrow, glassgow\n",
    "* Now, bottom, slightly towards left, we can see terms related to time clustered together - later, close, min, current, hours, prior, daily\n",
    "* In the top slightly towards left , we see a cluster that is related to passenger information - address, surname etc\n",
    "\n",
    "Be sure to try the interactive version by running the kernel and mouse over the points to find other clusters, that's where all the fun of Scattertext is!\n",
    "\n",
    "Scattertext has many more interesting visualisations like this, do check out its [documentation](https://github.com/JasonKessler/scattertext)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "355307a6f4410463c9d2f4a770afcf12a7e378a0"
   },
   "source": [
    "A lot more can be done using this dataset and I hope you've got some good ideas to extend this work. This kernel depends on a lot of custom packages, so if you fork and build on top of this kernel, make sure to install the following custom pip packages from the Kaggle Kernel settings interface : vaderSentiment, spacymoji, spacy-cld, scattertext and empath.\n",
    "\n",
    "Hope this inspired you to try out the different Spacy Extensions available to your own text data.\n",
    "\n",
    "Thank you :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "39751a13337cd09b32588e2d0fc5f7e7817cca8b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
